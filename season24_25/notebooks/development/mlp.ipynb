{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential hyper-parameters to tune: weight_decay, dropout_prob, number of hidden layers and their sizes\n",
    "\n",
    "Add tensorboard for following training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import calculate_performance_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model and other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, dropout_prob=0.2):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        # Initialize an empty list to hold layers\n",
    "        layers = []\n",
    "\n",
    "        # Input layer to the first hidden layer\n",
    "        layers.append(nn.Linear(input_size, hidden_sizes[0]))\n",
    "        layers.append(nn.ReLU())  # Activation function\n",
    "\n",
    "        # Create hidden layers dynamically based on hidden_sizes\n",
    "        for i in range(1, len(hidden_sizes)):\n",
    "            layers.append(nn.Linear(hidden_sizes[i-1], hidden_sizes[i]))\n",
    "            layers.append(nn.BatchNorm1d(hidden_sizes[i])) # Batch Normalization\n",
    "            layers.append(nn.ReLU())  # Activation function for each hidden layer\n",
    "            layers.append(nn.Dropout(dropout_prob))\n",
    "\n",
    "        # Output layer (last hidden layer to output)\n",
    "        layers.append(nn.Linear(hidden_sizes[-1], output_size))\n",
    "\n",
    "        # Use nn.Sequential to create the full model from the list of layers\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to average model weights\n",
    "def average_model_weights(models):\n",
    "    avg_model = copy.deepcopy(models[0])  # Create a copy of the first model\n",
    "    with torch.no_grad():  # Turn off gradient tracking\n",
    "        for key in avg_model.state_dict().keys():\n",
    "            for i in range(1, len(models)):\n",
    "                avg_model.state_dict()[key] += models[i].state_dict()[key]\n",
    "            avg_model.state_dict()[key] = avg_model.state_dict()[key] / len(models)\n",
    "    return avg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping Class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = np.Inf\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.best_model_state = copy.deepcopy(model.state_dict())  # Save best model state\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(models, X):\n",
    "    with torch.no_grad():\n",
    "        predictions = [model(X) for model in models]\n",
    "    return torch.mean(torch.stack(predictions), dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_gameweek = 0\n",
    "shift_param = 1\n",
    "\n",
    "# fetch data\n",
    "filepath = Path('../../data/modeling/fpl_df.csv')\n",
    "fpl_df = pd.read_csv(filepath, index_col=0, low_memory=False)\n",
    "fpl_df['data_retrieved_datetime'] = pd.to_datetime(fpl_df['data_retrieved_datetime'])\n",
    "display(fpl_df.head())\n",
    "display(fpl_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_no_shift = ['element_type', 'home', 'opponent_xG_ewm_5', 'opponent_xG_ewm_10',\n",
    "       'opponent_xG_ewm_20', 'opponent_xG_ewm_40', 'opponent_xGA_ewm_5',\n",
    "       'opponent_xGA_ewm_10', 'opponent_xGA_ewm_20',\n",
    "       'opponent_xGA_ewm_40', ]\n",
    "\n",
    "features_shift = ['corners_and_indirect_freekicks_order', 'creativity_rank', \n",
    "       'direct_freekicks_order', 'ict_index_rank', 'influence_rank',\n",
    "       'minutes', 'now_cost', 'penalties_order', 'points_per_game', \n",
    "       'selected_by_percent', 'threat_rank',\n",
    "       'team_xG_ewm_5', 'team_xG_ewm_10', 'team_xG_ewm_20',\n",
    "       'team_xG_ewm_40', 'team_xGA_ewm_5', 'team_xGA_ewm_10',\n",
    "       'team_xGA_ewm_20', 'team_xGA_ewm_40', \n",
    "       'gameweek_assists_ewm_5', 'gameweek_bps_ewm_5',\n",
    "       'gameweek_creativity_ewm_5', 'event_points_ewm_5',\n",
    "       'gameweek_goals_scored_ewm_5', 'gameweek_goals_conceded_ewm_5',\n",
    "       'gameweek_saves_ewm_5', 'gameweek_threat_ewm_5',\n",
    "       'gameweek_xG_ewm_5', 'gameweek_xA_ewm_5', 'gameweek_xGA_ewm_5',\n",
    "       'gameweek_minutes_ewm_5', 'gameweek_xPoints_ewm_5',\n",
    "       'gameweek_assists_ewm_10', 'gameweek_bps_ewm_10',\n",
    "       'gameweek_creativity_ewm_10', 'event_points_ewm_10',\n",
    "       'gameweek_goals_scored_ewm_10', 'gameweek_goals_conceded_ewm_10',\n",
    "       'gameweek_saves_ewm_10', 'gameweek_threat_ewm_10',\n",
    "       'gameweek_xG_ewm_10', 'gameweek_xA_ewm_10', 'gameweek_xGA_ewm_10',\n",
    "       'gameweek_minutes_ewm_10', 'gameweek_xPoints_ewm_10',\n",
    "       'gameweek_assists_ewm_20', 'gameweek_bps_ewm_20',\n",
    "       'gameweek_creativity_ewm_20', 'event_points_ewm_20',\n",
    "       'gameweek_goals_scored_ewm_20', 'gameweek_goals_conceded_ewm_20',\n",
    "       'gameweek_saves_ewm_20', 'gameweek_threat_ewm_20',\n",
    "       'gameweek_xG_ewm_20', 'gameweek_xA_ewm_20', 'gameweek_xGA_ewm_20',\n",
    "       'gameweek_minutes_ewm_20', 'gameweek_xPoints_ewm_20',\n",
    "       'gameweek_assists_ewm_40', 'gameweek_bps_ewm_40',\n",
    "       'gameweek_creativity_ewm_40', 'event_points_ewm_40',\n",
    "       'gameweek_goals_scored_ewm_40', 'gameweek_goals_conceded_ewm_40',\n",
    "       'gameweek_saves_ewm_40', 'gameweek_threat_ewm_40',\n",
    "       'gameweek_xG_ewm_40', 'gameweek_xA_ewm_40', 'gameweek_xGA_ewm_40',\n",
    "       'gameweek_minutes_ewm_40', 'gameweek_xPoints_ewm_40',\n",
    "       'gameweek_assists_expanding', 'gameweek_bps_expanding',\n",
    "       'gameweek_creativity_expanding', 'event_points_expanding',\n",
    "       'gameweek_goals_scored_expanding',\n",
    "       'gameweek_goals_conceded_expanding', 'gameweek_saves_expanding',\n",
    "       'gameweek_threat_expanding', 'gameweek_xG_expanding',\n",
    "       'gameweek_xA_expanding', 'gameweek_xGA_expanding',\n",
    "       'gameweek_minutes_expanding', 'gameweek_xPoints_expanding',\n",
    "       'gameweek_assists_expanding_per90', 'gameweek_bps_expanding_per90',\n",
    "       'gameweek_creativity_expanding_per90',\n",
    "       'event_points_expanding_per90',\n",
    "       'gameweek_goals_scored_expanding_per90',\n",
    "       'gameweek_goals_conceded_expanding_per90',\n",
    "       'gameweek_saves_expanding_per90',\n",
    "       'gameweek_threat_expanding_per90', 'gameweek_xG_expanding_per90',\n",
    "       'gameweek_xA_expanding_per90', 'gameweek_xGA_expanding_per90',\n",
    "       'gameweek_xPoints_expanding_per90', 'xG_overperformance'\n",
    "    ]\n",
    "\n",
    "target = ['event_points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift given features\n",
    "df = fpl_df.copy()\n",
    "df[features_shift] = df.groupby(['first_name', 'second_name'])[features_shift].shift(shift_param)\n",
    "display(df.head())\n",
    "display(df.tail())\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum(axis=1).plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where too much data missing\n",
    "df = df[df.isnull().sum(axis=1) <= 90].reset_index(drop=True)\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = df[~(df.data_retrieved_datetime>'1-1-2024')].index\n",
    "display(train_index)\n",
    "test_index = df[(df.data_retrieved_datetime>'1-1-2024')].index\n",
    "display(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = df[features_no_shift+features_shift].copy()\n",
    "y_df = df[target].copy()\n",
    "X_train_df = df.loc[train_index, features_no_shift+features_shift].copy()\n",
    "y_train_df = df.loc[train_index, target].copy()\n",
    "X_test_df = df.loc[test_index, features_no_shift+features_shift].copy()\n",
    "y_test_df = df.loc[test_index, target].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit input data scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit input data imputation\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median', keep_empty_features=True)\n",
    "\n",
    "# preprocessing pipeline\n",
    "preprocess_pipeline = Pipeline([\n",
    "            (\"scaler\", scaler),\n",
    "            (\"imputer\", imputer),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess input data\n",
    "X_train = preprocess_pipeline.fit_transform(X_train_df)\n",
    "X_test = preprocess_pipeline.transform(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Pandas DataFrame to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train_df.values, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test_df.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = X_train.shape[1]\n",
    "hidden_sizes = [64, 32, 16, 8] # 64, 32, 16, 8\n",
    "output_size = y_train.shape[1]\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "k_folds = 3  # Number of folds for cross-validation\n",
    "patience = 10  # Number of epochs with no improvement for early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross Validation\n",
    "kf = KFold(n_splits=k_folds, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize for storing fold results\n",
    "fold_models = []\n",
    "fold_performance = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold cross-validation loop\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "    print(f'Fold {fold + 1}/{k_folds}')\n",
    "    \n",
    "    # Create DataLoader for training and validation sets\n",
    "    train_dataset = Subset(TensorDataset(X_train, y_train), train_idx)\n",
    "    val_dataset = Subset(TensorDataset(X_train, y_train), val_idx)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    \n",
    "    # Instantiate the model, loss function, and optimizer\n",
    "    model = MLP(input_size, hidden_sizes, output_size)\n",
    "    criterion = nn.MSELoss(reduction='sum')  # Mean Squared Error loss for regression\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    \n",
    "    # Early stopping instance\n",
    "    early_stopping = EarlyStopping(patience=patience)\n",
    "\n",
    "    # Training loop with early stopping\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            # Forward pass\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation after every epoch\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                val_outputs = model(batch_X)\n",
    "                val_loss += criterion(val_outputs, batch_y).item()\n",
    "\n",
    "        val_loss /= len(val_dataset)  # Average validation loss\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Fold {fold+1}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "        # Early stopping check\n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:            \n",
    "            print(f\"Early stopping at epoch {epoch+1} for fold {fold+1}\")\n",
    "            # Load the best model state when early stopping is triggered\n",
    "            model.load_state_dict(early_stopping.best_model_state)\n",
    "            break\n",
    "\n",
    "    print(f'Fold {fold + 1}, Validation Loss: {val_loss:.4f}')\n",
    "    fold_performance.append(val_loss)\n",
    "    \n",
    "    # Save the model for this fold\n",
    "    fold_models.append(copy.deepcopy(model))\n",
    "\n",
    "# Average the weights from all fold models\n",
    "average_model = average_model_weights(fold_models)\n",
    "\n",
    "# Final performance across folds\n",
    "avg_performance = np.mean(fold_performance)\n",
    "print(f'Average Validation Loss across {k_folds} folds: {avg_performance:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: test final model, save final model + preprocessing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average model mse\n",
    "\n",
    "average_model.eval() # Set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    predictions = average_model(X_test)\n",
    "criterion(predictions, y_test).item() / X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae, rmse, r2 = calculate_performance_metrics(y_test.numpy().flatten(), predictions.numpy().flatten())\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R^2: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test individual models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(fold_models)):\n",
    "    with torch.no_grad():\n",
    "        predictions = fold_models[i](X_test)\n",
    "    mse = criterion(predictions, y_test).item() / X_test.shape[0]\n",
    "    mae, rmse, r2 = calculate_performance_metrics(y_test.numpy().flatten(), predictions.numpy().flatten())\n",
    "    print(f'MSE: {mse}')\n",
    "    print(f'RMSE: {rmse}')\n",
    "    print(f'R^2: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions on test set\n",
    "predictions = ensemble_predict(fold_models, X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test mse\n",
    "criterion(predictions, y_test).item() / X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae, rmse, r2 = calculate_performance_metrics(y_test.numpy().flatten(), predictions.numpy().flatten())\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R^2: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check predictions in the test set for a particular player\n",
    "player_name = 'Salah'\n",
    "aux = df[df['name'].notnull()].copy()\n",
    "aux = aux.loc[aux['name'].str.contains(player_name)]\n",
    "aux = aux[features_no_shift+features_shift]\n",
    "aux.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = preprocess_pipeline.transform(aux.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(sum(np.isnan(aux)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum(sum(np.isnan(aux)))\n",
    "aux.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_predict(fold_models, torch.tensor(aux, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_models[0](torch.tensor(aux.values, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv23-24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
