{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_param = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import datetime as dt\n",
    "import pickle\n",
    "\n",
    "from src.utils import fetch_latest_fpl_data\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import poisson\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model for estimating bonus points based on gameweek bps\n",
    "model_path = Path(f\"../models/logistic_regression_for_bonus_points.pkl\")\n",
    "with open(model_path, \"rb\") as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fpl_data_processing(df, columns):\n",
    "\n",
    "    xg_data = []\n",
    "    xa_data = []\n",
    "    xga_data = []\n",
    "    for ix, row in df.iterrows():\n",
    "        my_gameweek = row['gameweek']\n",
    "        xg_data.append( row[f'xG_week{my_gameweek}'] )\n",
    "        xa_data.append( row[f'xA_week{my_gameweek}'] )\n",
    "        xga_data.append( row[f'xGA_week{my_gameweek}'] )\n",
    "\n",
    "    df['gameweek_xG'] = xg_data\n",
    "    df['gameweek_xA'] = xa_data\n",
    "    df['gameweek_xGA'] = xga_data\n",
    "\n",
    "    df_new = df[columns].copy()\n",
    "\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_fill_na(x, gameweek_col, diff_col):\n",
    "    '''Fill nan values for first items for grouped variables where diff is calculated. But also don't fill for season 22-23,\n",
    "    where data is missing for a number of weeks at the beginning of the season.'''\n",
    "    my_value = x[diff_col] if (np.isnan(x[gameweek_col])) & (x['minutes']<=90) else x[gameweek_col]\n",
    "    return my_value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_xPoints(x,clf):\n",
    "    \"\"\"Expected points for a given gameweek given underlying stats for that gameweek.\"\"\"\n",
    "\n",
    "    clean_sheet_points = np.array([4,4,1,0])\n",
    "    goal_points = np.array([6,6,5,4])\n",
    "\n",
    "    # calculate expexted points\n",
    "    points_played = np.array([1 if x['gameweek_minutes']>0 else 0])\n",
    "    points_played_over_60 = np.array([1 if x['gameweek_minutes']>=60 else 0])\n",
    "    points_xG = goal_points[x['element_type']-1] * x['gameweek_xG']\n",
    "    points_xA = x['gameweek_xA'] * 3\n",
    "    clean_sheet_probability = np.array(poisson.pmf(0,x['team_xGA']))\n",
    "    points_clean_sheet = [clean_sheet_points[x['element_type']-1] * clean_sheet_probability if x['gameweek_minutes']>=60 else 0]\n",
    "    points_saves = x['gameweek_saves'] // 3\n",
    "    points_penalty_saves = x['gameweek_penalties_saved'] * 5 * 0.21 #points for save times approx. probability of penalty save\n",
    "    #penalty_for_penalty_miss = x['Performance_PKatt'] * (-2*0.21) # this data only on fbref\n",
    "    # estimate bonus points\n",
    "    if not np.isnan(x['gameweek_bps']):\n",
    "        y_pred_prob = clf.predict_proba(np.array(x['gameweek_bps']).reshape(-1, 1))\n",
    "    else:\n",
    "        # return nan if bonus points can't be estimated \n",
    "        return np.nan\n",
    "    points_bonus = np.matmul(y_pred_prob, np.array([0,1,2,3]).reshape((4,1)))\n",
    "    \n",
    "    # penalty for possible points deductions based on goals conceded\n",
    "    xGA = x['team_xGA']\n",
    "    # calculate penalty\n",
    "    xGA_conceded_penalty = -(poisson.pmf(2,xGA)+poisson.pmf(3,xGA))-(poisson.pmf(4,xGA)+poisson.pmf(5,xGA))-(poisson.pmf(6,xGA)+poisson.pmf(7,xGA))-(poisson.pmf(8,xGA)+poisson.pmf(9,xGA)-(poisson.pmf(10,xGA)+poisson.pmf(11,xGA)))\n",
    "    # apply penalty only to GK and DEF\n",
    "    if (x['element_type']==1) | (x['element_type']==2):\n",
    "        xGA_conceded_penalty = xGA_conceded_penalty\n",
    "    else:\n",
    "        xGA_conceded_penalty = 0\n",
    "    # scale penalty with playing time\n",
    "    xGA_conceded_penalty = (x['gameweek_minutes'] / 90) * xGA_conceded_penalty\n",
    "\n",
    "    penalty_for_cards = [-3 if x['gameweek_red_cards']==1 else -1 if x['gameweek_yellow_cards']==1 else 0]\n",
    "    penalty_for_own_goal = -2 * x['gameweek_own_goals']\n",
    "\n",
    "    # add up all point components\n",
    "    total_points = float(points_played + points_played_over_60 + points_xG + points_xA + points_clean_sheet + points_saves +\\\n",
    "                    points_penalty_saves + points_bonus + xGA_conceded_penalty +\\\n",
    "                    penalty_for_cards + penalty_for_own_goal)\n",
    "    \n",
    "    return total_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpl data from previous seasons\n",
    "filepath = Path('../data/modeling/fpl_df.csv')\n",
    "fpl_df = pd.read_csv(filepath, index_col=0)\n",
    "display(fpl_df.head())\n",
    "display(fpl_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpl data from this season\n",
    "fpl_df_new = fetch_latest_fpl_data()\n",
    "display(fpl_df_new.head())\n",
    "display(fpl_df_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate new fpl data with old\n",
    "fpl_df = pd.concat([fpl_df, fpl_df_new], join='outer').reset_index(drop=True)\n",
    "display(fpl_df.head())\n",
    "display(fpl_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running team data from past seasons\n",
    "filepath = Path('../data/modeling/team_data.csv')\n",
    "team_data = pd.read_csv(filepath, index_col=0)\n",
    "display(team_data.head())\n",
    "display(team_data.tail())\n",
    "display(team_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpl fixtures data from this season\n",
    "filepath = Path('../data/fixtures/fpl_fixtures.csv')\n",
    "fixtures_fpl = pd.read_csv(filepath, index_col=0)\n",
    "fixtures_fpl = fixtures_fpl[fixtures_fpl.finished]\n",
    "display(fixtures_fpl.head())\n",
    "display(fixtures_fpl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fbref fixtures data from this season\n",
    "filepath = Path('../data/fixtures/fbref_fixtures.csv')\n",
    "fixtures_fbref = pd.read_csv(filepath, index_col=0)\n",
    "display(fixtures_fbref.head())\n",
    "display(fixtures_fbref.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process FPL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find how many minutes a player played on a given gameweek\n",
    "fpl_df['gameweek_minutes'] = fpl_df.groupby(['first_name', 'second_name', 'season'])['minutes'].diff()\n",
    "# fill na caused at the start of each season by taking diff (but don't fill for season 22-23 where early season data is missing)\n",
    "fpl_df['gameweek_minutes'] = fpl_df.apply(lambda x: my_fill_na(x, 'gameweek_minutes', 'minutes'), axis=1)\n",
    "print('Number of rows with zero minutes played in a gameweek:')\n",
    "display(fpl_df[fpl_df.gameweek_minutes==0].shape[0])\n",
    "print('Number of rows with over 90 minutes played in a gameweek:')\n",
    "display(fpl_df[fpl_df.gameweek_minutes>90].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check does the latest season have any problem data (ok if '23-24' does not appear here)\n",
    "display(fpl_df.loc[fpl_df.gameweek_minutes>90, 'season'].unique())\n",
    "display(fpl_df.loc[fpl_df.gameweek_minutes==0, 'season'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with 0 minutes or more than 90 minutes\n",
    "fpl_df = fpl_df[(fpl_df.gameweek_minutes>0) & (fpl_df.gameweek_minutes<=90)].reset_index(drop=True)\n",
    "display(fpl_df.head())\n",
    "display(fpl_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add xG data to FPL fixtures data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map fbref team names to fpl team names\n",
    "fbref_teams = np.sort(pd.concat([fixtures_fbref.Home, fixtures_fbref.Away]).unique())\n",
    "team_name_dict = dict(zip(fbref_teams, np.sort(fixtures_fpl.home_team.unique())))\n",
    "display(team_name_dict)\n",
    "\n",
    "fixtures_fbref['Home'] = fixtures_fbref['Home'].apply(lambda x: team_name_dict[x])\n",
    "fixtures_fbref['Away'] = fixtures_fbref['Away'].apply(lambda x: team_name_dict[x])\n",
    "display(fixtures_fbref.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_xg = []\n",
    "away_xg = []\n",
    "for ix, row in fixtures_fpl.iterrows():\n",
    "    home_team = row.home_team\n",
    "    away_team = row.away_team\n",
    "    home_team_xg = fixtures_fbref.loc[(fixtures_fbref['Home']==home_team) & (fixtures_fbref['Away']==away_team), 'xG_home'].values[0]\n",
    "    away_team_xg = fixtures_fbref.loc[(fixtures_fbref['Home']==home_team) & (fixtures_fbref['Away']==away_team), 'xG_away'].values[0]\n",
    "    home_xg.append( home_team_xg )\n",
    "    away_xg.append( away_team_xg )\n",
    "\n",
    "fixtures_fpl['xg_home'] = home_xg\n",
    "fixtures_fpl['xg_away'] = away_xg\n",
    "\n",
    "display(fixtures_fpl.head())\n",
    "print('Nulls:')\n",
    "display(fixtures_fpl[['xg_home', 'xg_away']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv23-24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
