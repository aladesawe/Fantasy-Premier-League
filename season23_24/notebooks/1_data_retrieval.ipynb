{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_gameweek = 1\n",
    "shift_param = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import datetime as dt\n",
    "import pickle\n",
    "import json\n",
    "import requests\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import poisson\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model for estimating bonus points based on gameweek bps\n",
    "model_path = Path(f\"../models/logistic_regression_for_bonus_points.pkl\")\n",
    "with open(model_path, \"rb\") as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fpl_data_processing(df, columns):\n",
    "\n",
    "    xg_data = []\n",
    "    xa_data = []\n",
    "    xga_data = []\n",
    "    for ix, row in df.iterrows():\n",
    "        my_gameweek = row['gameweek']\n",
    "        xg_data.append( row[f'xG_week{my_gameweek}'] )\n",
    "        xa_data.append( row[f'xA_week{my_gameweek}'] )\n",
    "        xga_data.append( row[f'xGA_week{my_gameweek}'] )\n",
    "\n",
    "    df['gameweek_xG'] = xg_data\n",
    "    df['gameweek_xA'] = xa_data\n",
    "    df['gameweek_xGA'] = xga_data\n",
    "\n",
    "    df_new = df[columns].copy()\n",
    "\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_fill_na(x, gameweek_col, diff_col):\n",
    "    '''Fill nan values for first items for grouped variables where diff is calculated. But also don't fill for season 22-23,\n",
    "    where data is missing for a number of weeks at the beginning of the season.'''\n",
    "    my_value = x[diff_col] if (np.isnan(x[gameweek_col])) & (x['minutes']<=90) else x[gameweek_col]\n",
    "    return my_value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_xPoints(x,clf):\n",
    "    \"\"\"Expected points for a given gameweek given underlying stats for that gameweek.\"\"\"\n",
    "\n",
    "    clean_sheet_points = np.array([4,4,1,0])\n",
    "    goal_points = np.array([6,6,5,4])\n",
    "\n",
    "    # calculate expexted points\n",
    "    points_played = np.array([1 if x['gameweek_minutes']>0 else 0])\n",
    "    points_played_over_60 = np.array([1 if x['gameweek_minutes']>=60 else 0])\n",
    "    points_xG = goal_points[x['element_type']-1] * x['gameweek_xG']\n",
    "    points_xA = x['gameweek_xA'] * 3\n",
    "    clean_sheet_probability = np.array(poisson.pmf(0,x['team_xGA']))\n",
    "    points_clean_sheet = [clean_sheet_points[x['element_type']-1] * clean_sheet_probability if x['gameweek_minutes']>=60 else 0]\n",
    "    points_saves = x['gameweek_saves'] // 3\n",
    "    points_penalty_saves = x['gameweek_penalties_saved'] * 5 * 0.21 #points for save times approx. probability of penalty save\n",
    "    #penalty_for_penalty_miss = x['Performance_PKatt'] * (-2*0.21) # this data only on fbref\n",
    "    # estimate bonus points\n",
    "    if not np.isnan(x['gameweek_bps']):\n",
    "        y_pred_prob = clf.predict_proba(np.array(x['gameweek_bps']).reshape(-1, 1))\n",
    "    else:\n",
    "        # return nan if bonus points can't be estimated \n",
    "        return np.nan\n",
    "    points_bonus = np.matmul(y_pred_prob, np.array([0,1,2,3]).reshape((4,1)))\n",
    "    \n",
    "    # penalty for possible points deductions based on goals conceded\n",
    "    xGA = x['team_xGA']\n",
    "    # calculate penalty\n",
    "    xGA_conceded_penalty = -(poisson.pmf(2,xGA)+poisson.pmf(3,xGA))-(poisson.pmf(4,xGA)+poisson.pmf(5,xGA))-(poisson.pmf(6,xGA)+poisson.pmf(7,xGA))-(poisson.pmf(8,xGA)+poisson.pmf(9,xGA)-(poisson.pmf(10,xGA)+poisson.pmf(11,xGA)))\n",
    "    # apply penalty only to GK and DEF\n",
    "    if (x['element_type']==1) | (x['element_type']==2):\n",
    "        xGA_conceded_penalty = xGA_conceded_penalty\n",
    "    else:\n",
    "        xGA_conceded_penalty = 0\n",
    "    # scale penalty with playing time\n",
    "    xGA_conceded_penalty = (x['gameweek_minutes'] / 90) * xGA_conceded_penalty\n",
    "\n",
    "    penalty_for_cards = [-3 if x['gameweek_red_cards']==1 else -1 if x['gameweek_yellow_cards']==1 else 0]\n",
    "    penalty_for_own_goal = -2 * x['gameweek_own_goals']\n",
    "\n",
    "    # add up all point components\n",
    "    total_points = float(points_played + points_played_over_60 + points_xG + points_xA + points_clean_sheet + points_saves +\\\n",
    "                    points_penalty_saves + points_bonus + xGA_conceded_penalty +\\\n",
    "                    penalty_for_cards + penalty_for_own_goal)\n",
    "    \n",
    "    return total_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teams for season 23-24\n",
    "teams = ['Arsenal', 'Aston Villa', 'Bournemouth', 'Brentford', 'Brighton',\n",
    "         'Burnley', 'Chelsea', 'Crystal Palace', 'Everton', 'Fulham',\n",
    "         'Liverpool', 'Luton', 'Manchester City', 'Manchester Utd',\n",
    "         'Newcastle Utd', 'Nottingham Forest', 'Sheffield Utd', 'Tottenham',\n",
    "         'West Ham', 'Wolves']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch FPL data online\n",
    "fpl_online_data = json.loads(requests.get('https://fantasy.premierleague.com/api/bootstrap-static/').text)\n",
    "fpl_online_df = pd.DataFrame(fpl_online_data['elements'])\n",
    "fpl_online_df['team_name'] = [teams[i] for i in fpl_online_df['team']-1]\n",
    "fpl_online_df['name'] = fpl_online_df.apply(lambda x: x['first_name'] + ' ' + x['second_name'], axis=1)\n",
    "fpl_online_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE NEW DATA SET IF THERE IS NEW DATA AVAILABLE AND SAVE TO FILE\n",
    "\n",
    "# fetch latest fpl data from data folder\n",
    "folder_path_str = '../data/fpl/'\n",
    "folder_path = Path(folder_path_str)\n",
    "files = os.listdir(folder_path)\n",
    "# drop non-csv files (e.g. DS_Store)\n",
    "files = [file for file in files if file.endswith('.csv')]\n",
    "# sort files and pick last one\n",
    "files = np.sort(files)\n",
    "file = files[-1]\n",
    "full_path = folder_path_str + file\n",
    "old_data = pd.read_csv(full_path, index_col=0)\n",
    "\n",
    "# only take players who have played, i.e., minutes>0\n",
    "new_data = fpl_online_df[fpl_online_df.minutes>0].copy()\n",
    "# players who have now played but had not previously played at all\n",
    "new_data_1 = new_data[~new_data.name.isin(old_data.name.unique())].copy()\n",
    "# players whose minutes are higher now than previously\n",
    "aux = new_data[new_data.name.isin(old_data.name.unique())].copy()\n",
    "new_rows = []\n",
    "for ix, row in aux.iterrows():\n",
    "    player_name = row['name']\n",
    "    change_in_minutes = row['minutes'] - old_data.loc[old_data.name==player_name, 'minutes'].iloc[-1]\n",
    "    if change_in_minutes > 0:\n",
    "        new_rows.append(row)\n",
    "if len(new_rows) > 0:\n",
    "    new_data_2 = pd.concat([new_rows])\n",
    "else:\n",
    "    new_data_2 = pd.DataFrame() # empty df\n",
    "\n",
    "# overwrites old new_data variable\n",
    "new_data = pd.concat([new_data_1, new_data_2], ignore_index=True)\n",
    "\n",
    "# create new data set combining old and new data and save to file\n",
    "if new_data.shape[0] > 0:\n",
    "\n",
    "\n",
    "\n",
    "    # add info\n",
    "    new_data['gameweek'] = latest_gameweek\n",
    "    new_data['season'] = '23-24'\n",
    "    time_now = dt.datetime.now()\n",
    "    new_data['data_retrieved_datetime'] = time_now\n",
    "    display(new_data)\n",
    "\n",
    "    full_data = pd.concat([old_data, new_data], ignore_index=True)\n",
    "    print(f'Full data shape: {full_data.shape}')\n",
    "    \n",
    "    # save new full data\n",
    "    path = Path('../data/fpl/data_' + str(time_now.strftime(\"%Y%m%d-%H%M%S\")) + '.csv')\n",
    "    full_data.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv23-24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
